{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.5' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Saketh/AppData/Local/Programs/Python/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "from mimesis import Generic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Faker and Mimesis\n",
    "fake = Faker()\n",
    "generic = Generic(\"en\")\n",
    "\n",
    "# Define the number of records\n",
    "n_records = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "data = {\n",
    "    \"Power_Plant_ID\": [fake.unique.uuid4() for _ in range(n_records)],  # Unique identifiers\n",
    "    \"Plant_Location\": [fake.city() for _ in range(n_records)],  # Plant location\n",
    "    \"Operating_Capacity_MW\": [generic.random.uniform(50, 1000) for _ in range(n_records)],  # MW capacity\n",
    "    \"Fuel_Type\": np.random.choice([\"Coal\", \"Gas\", \"Nuclear\", \"Renewable\"], size=n_records, p=[0.3, 0.3, 0.2, 0.2]),\n",
    "    \"Emission_Level_CO2_tonnes\": [generic.random.uniform(1000, 50000) for _ in range(n_records)],  # CO2 emissions\n",
    "    \"Operational_Years\": [generic.random.randint(1, 60) for _ in range(n_records)],  # Plant age in years\n",
    "    \"Maintenance_Cost_MUSD\": [generic.random.uniform(0.5, 20) for _ in range(n_records)],  # Maintenance cost\n",
    "    \"Temperature_C\": [generic.random.uniform(15, 45) for _ in range(n_records)],  # Surrounding temperature\n",
    "    \"Humidity_percent\": [generic.random.uniform(20, 90) for _ in range(n_records)],  # Humidity\n",
    "    \"Wind_Speed_kmh\": [generic.random.uniform(0, 100) for _ in range(n_records)],  # Wind speed\n",
    "    \"Soil_Moisture_percent\": [generic.random.uniform(5, 40) for _ in range(n_records)],  # Soil moisture\n",
    "    \"Dam_Height_m\": [generic.random.uniform(30, 300) for _ in range(n_records)],  # Dam height\n",
    "    \"Reservoir_Capacity_MCM\": [generic.random.uniform(10, 5000) for _ in range(n_records)],  # Reservoir capacity\n",
    "    \"Sedimentation_Rate_mpy\": [generic.random.uniform(0.1, 1) for _ in range(n_records)],  # Sedimentation rate\n",
    "    \"Efficiency_percent\": [generic.random.uniform(60, 95) for _ in range(n_records)],  # Power plant efficiency\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing values\n",
    "for col in [\"Operating_Capacity_MW\", \"Emission_Level_CO2_tonnes\", \"Efficiency_percent\"]:\n",
    "    indices = np.random.choice(n_records, size=20, replace=False)\n",
    "    for idx in indices:\n",
    "        data[col][idx] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce outliers\n",
    "outlier_indices = np.random.choice(n_records, size=10, replace=False)\n",
    "for idx in outlier_indices:\n",
    "    data[\"Emission_Level_CO2_tonnes\"][idx] = data[\"Emission_Level_CO2_tonnes\"][idx] * 10  # Extreme outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce duplicates (copy some random rows and append them)\n",
    "duplicate_indices = np.random.choice(n_records, size=50, replace=False)\n",
    "duplicated_data = pd.DataFrame(data).iloc[duplicate_indices]\n",
    "duplicated_data[\"Power_Plant_ID\"] = [fake.unique.uuid4() for _ in range(len(duplicated_data))]  # Generate unique IDs\n",
    "data.update(duplicated_data.to_dict(orient='list'))  # Update original data with duplicated rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise by slightly modifying numerical data\n",
    "noise_indices = np.random.choice(n_records, size=30, replace=False)\n",
    "for idx in noise_indices:\n",
    "    data[\"Operating_Capacity_MW\"][idx] += np.random.uniform(-50, 50)  # Add small random noise\n",
    "    data[\"Emission_Level_CO2_tonnes\"][idx] += np.random.uniform(-500, 500)  # Add small random noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"power_plant_dataset.csv\", index=False)\n",
    "print(\"Dataset created, saved as 'power_plant_dataset.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
